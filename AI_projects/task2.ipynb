{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('crane.png')\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = img.shape\n",
    "center = (width // 2, height // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "################################################################################\n",
    "# SPDX-FileCopyrightText: Copyright (c) 2019-2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "################################################################################\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import platform\n",
    "import configparser\n",
    "\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GLib, Gst\n",
    "from common.is_aarch_64 import is_aarch64\n",
    "from common.bus_call import bus_call\n",
    "\n",
    "import pyds\n",
    "\n",
    "PGIE_CLASS_ID_VEHICLE = 0\n",
    "PGIE_CLASS_ID_BICYCLE = 1\n",
    "PGIE_CLASS_ID_PERSON = 2\n",
    "PGIE_CLASS_ID_ROADSIGN = 3\n",
    "past_tracking_meta=[0]\n",
    "\n",
    "def osd_sink_pad_buffer_probe(pad,info,u_data):\n",
    "    frame_number=0\n",
    "    #Intiallizing object counter with 0.\n",
    "    obj_counter = {\n",
    "        PGIE_CLASS_ID_VEHICLE:0,\n",
    "        PGIE_CLASS_ID_PERSON:0,\n",
    "        PGIE_CLASS_ID_BICYCLE:0,\n",
    "        PGIE_CLASS_ID_ROADSIGN:0\n",
    "    }\n",
    "    num_rects=0\n",
    "    gst_buffer = info.get_buffer()\n",
    "    if not gst_buffer:\n",
    "        print(\"Unable to get GstBuffer \")\n",
    "        return\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    # Note that pyds.gst_buffer_get_nvds_batch_meta() expects the\n",
    "    # C address of gst_buffer as input, which is obtained with hash(gst_buffer)\n",
    "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame = batch_meta.frame_meta_list\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            # Note that l_frame.data needs a cast to pyds.NvDsFrameMeta\n",
    "            # The casting is done by pyds.NvDsFrameMeta.cast()\n",
    "            # The casting also keeps ownership of the underlying memory\n",
    "            # in the C code, so the Python garbage collector will leave\n",
    "            # it alone.\n",
    "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        frame_number=frame_meta.frame_num\n",
    "        num_rects = frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                # Casting l_obj.data to pyds.NvDsObjectMeta\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            obj_counter[obj_meta.class_id] += 1\n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        # Acquiring a display meta object. The memory ownership remains in\n",
    "        # the C code so downstream plugins can still access it. Otherwise\n",
    "        # the garbage collector will claim it when this probe function exits.\n",
    "        display_meta=pyds.nvds_acquire_display_meta_from_pool(batch_meta)\n",
    "        display_meta.num_labels = 1\n",
    "        py_nvosd_text_params = display_meta.text_params[0]\n",
    "        # Setting display text to be shown on screen\n",
    "        # Note that the pyds module allocates a buffer for the string, and the\n",
    "        # memory will not be claimed by the garbage collector.\n",
    "        # Reading the display_text field here will return the C address of the\n",
    "        # allocated string. Use pyds.get_string() to get the string content.\n",
    "        py_nvosd_text_params.display_text = \"Frame Number={} Number of Objects={} Vehicle_count={} Person_count={}\".format(frame_number, num_rects, obj_counter[PGIE_CLASS_ID_VEHICLE], obj_counter[PGIE_CLASS_ID_PERSON])\n",
    "\n",
    "        # Now set the offsets where the string should appear\n",
    "        py_nvosd_text_params.x_offset = 10\n",
    "        py_nvosd_text_params.y_offset = 12\n",
    "\n",
    "        # Font , font-color and font-size\n",
    "        py_nvosd_text_params.font_params.font_name = \"Serif\"\n",
    "        py_nvosd_text_params.font_params.font_size = 10\n",
    "        # set(red, green, blue, alpha); set to White\n",
    "        py_nvosd_text_params.font_params.font_color.set(1.0, 1.0, 1.0, 1.0)\n",
    "\n",
    "        # Text background color\n",
    "        py_nvosd_text_params.set_bg_clr = 1\n",
    "        # set(red, green, blue, alpha); set to Black\n",
    "        py_nvosd_text_params.text_bg_clr.set(0.0, 0.0, 0.0, 1.0)\n",
    "        # Using pyds.get_string() to get display_text as string\n",
    "        print(pyds.get_string(py_nvosd_text_params.display_text))\n",
    "        pyds.nvds_add_display_meta_to_frame(frame_meta, display_meta)\n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    #past traking meta data\n",
    "    if(past_tracking_meta[0]==1):\n",
    "        l_user=batch_meta.batch_user_meta_list\n",
    "        while l_user is not None:\n",
    "            try:\n",
    "                # Note that l_user.data needs a cast to pyds.NvDsUserMeta\n",
    "                # The casting is done by pyds.NvDsUserMeta.cast()\n",
    "                # The casting also keeps ownership of the underlying memory\n",
    "                # in the C code, so the Python garbage collector will leave\n",
    "                # it alone\n",
    "                user_meta=pyds.NvDsUserMeta.cast(l_user.data)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            if(user_meta and user_meta.base_meta.meta_type==pyds.NvDsMetaType.NVDS_TRACKER_PAST_FRAME_META):\n",
    "                try:\n",
    "                    # Note that user_meta.user_meta_data needs a cast to pyds.NvDsPastFrameObjBatch\n",
    "                    # The casting is done by pyds.NvDsPastFrameObjBatch.cast()\n",
    "                    # The casting also keeps ownership of the underlying memory\n",
    "                    # in the C code, so the Python garbage collector will leave\n",
    "                    # it alone\n",
    "                    pPastFrameObjBatch = pyds.NvDsPastFrameObjBatch.cast(user_meta.user_meta_data)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                for trackobj in pyds.NvDsPastFrameObjBatch.list(pPastFrameObjBatch):\n",
    "                    print(\"streamId=\",trackobj.streamID)\n",
    "                    print(\"surfaceStreamID=\",trackobj.surfaceStreamID)\n",
    "                    for pastframeobj in pyds.NvDsPastFrameObjStream.list(trackobj):\n",
    "                        print(\"numobj=\",pastframeobj.numObj)\n",
    "                        print(\"uniqueId=\",pastframeobj.uniqueId)\n",
    "                        print(\"classId=\",pastframeobj.classId)\n",
    "                        print(\"objLabel=\",pastframeobj.objLabel)\n",
    "                        for objlist in pyds.NvDsPastFrameObjList.list(pastframeobj):\n",
    "                            print('frameNum:', objlist.frameNum)\n",
    "                            print('tBbox.left:', objlist.tBbox.left)\n",
    "                            print('tBbox.width:', objlist.tBbox.width)\n",
    "                            print('tBbox.top:', objlist.tBbox.top)\n",
    "                            print('tBbox.right:', objlist.tBbox.height)\n",
    "                            print('confidence:', objlist.confidence)\n",
    "                            print('age:', objlist.age)\n",
    "            try:\n",
    "                l_user=l_user.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "    return Gst.PadProbeReturn.OK\t\n",
    "\n",
    "def main(args):\n",
    "    # Check input arguments\n",
    "    if(len(args)<2):\n",
    "        sys.stderr.write(\"usage: %s <h264_elementary_stream> [0/1]\\n\" % args[0])\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Standard GStreamer initialization\n",
    "    if(len(args)==3):\n",
    "        past_tracking_meta[0]=int(args[2])\n",
    "    Gst.init(None)\n",
    "\n",
    "    # Create gstreamer elements\n",
    "    # Create Pipeline element that will form a connection of other elements\n",
    "    print(\"Creating Pipeline \\n \")\n",
    "    pipeline = Gst.Pipeline()\n",
    "\n",
    "    if not pipeline:\n",
    "        sys.stderr.write(\" Unable to create Pipeline \\n\")\n",
    "\n",
    "    # Source element for reading from the file\n",
    "    print(\"Creating Source \\n \")\n",
    "    source = Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
    "    if not source:\n",
    "        sys.stderr.write(\" Unable to create Source \\n\")\n",
    "\n",
    "    # Since the data format in the input file is elementary h264 stream,\n",
    "    # we need a h264parser\n",
    "    print(\"Creating H264Parser \\n\")\n",
    "    h264parser = Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
    "    if not h264parser:\n",
    "        sys.stderr.write(\" Unable to create h264 parser \\n\")\n",
    "\n",
    "    # Use nvdec_h264 for hardware accelerated decode on GPU\n",
    "    print(\"Creating Decoder \\n\")\n",
    "    decoder = Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "    if not decoder:\n",
    "        sys.stderr.write(\" Unable to create Nvv4l2 Decoder \\n\")\n",
    "\n",
    "    # Create nvstreammux instance to form batches from one or more sources.\n",
    "    streammux = Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
    "    if not streammux:\n",
    "        sys.stderr.write(\" Unable to create NvStreamMux \\n\")\n",
    "\n",
    "    # Use nvinfer to run inferencing on decoder's output,\n",
    "    # behaviour of inferencing is set through config file\n",
    "    pgie = Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
    "    if not pgie:\n",
    "        sys.stderr.write(\" Unable to create pgie \\n\")\n",
    "\n",
    "    tracker = Gst.ElementFactory.make(\"nvtracker\", \"tracker\")\n",
    "    if not tracker:\n",
    "        sys.stderr.write(\" Unable to create tracker \\n\")\n",
    "\n",
    "    sgie1 = Gst.ElementFactory.make(\"nvinfer\", \"secondary1-nvinference-engine\")\n",
    "    if not sgie1:\n",
    "        sys.stderr.write(\" Unable to make sgie1 \\n\")\n",
    "\n",
    "\n",
    "    sgie2 = Gst.ElementFactory.make(\"nvinfer\", \"secondary2-nvinference-engine\")\n",
    "    if not sgie2:\n",
    "        sys.stderr.write(\" Unable to make sgie2 \\n\")\n",
    "\n",
    "    sgie3 = Gst.ElementFactory.make(\"nvinfer\", \"secondary3-nvinference-engine\")\n",
    "    if not sgie3:\n",
    "        sys.stderr.write(\" Unable to make sgie3 \\n\")\n",
    "\n",
    "    nvvidconv = Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor\")\n",
    "    if not nvvidconv:\n",
    "        sys.stderr.write(\" Unable to create nvvidconv \\n\")\n",
    "\n",
    "    # Create OSD to draw on the converted RGBA buffer\n",
    "    nvosd = Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
    "\n",
    "    if not nvosd:\n",
    "        sys.stderr.write(\" Unable to create nvosd \\n\")\n",
    "\n",
    "    # Finally render the osd output\n",
    "    if is_aarch64():\n",
    "        print(\"Creating nv3dsink \\n\")\n",
    "        sink = Gst.ElementFactory.make(\"nv3dsink\", \"nv3d-sink\")\n",
    "        if not sink:\n",
    "            sys.stderr.write(\" Unable to create nv3dsink \\n\")\n",
    "    else:\n",
    "        print(\"Creating EGLSink \\n\")\n",
    "        sink = Gst.ElementFactory.make(\"nveglglessink\", \"nvvideo-renderer\")\n",
    "        if not sink:\n",
    "            sys.stderr.write(\" Unable to create egl sink \\n\")\n",
    "\n",
    "    print(\"Playing file %s \" %args[1])\n",
    "    source.set_property('location', args[1])\n",
    "    streammux.set_property('width', 1920)\n",
    "    streammux.set_property('height', 1080)\n",
    "    streammux.set_property('batch-size', 1)\n",
    "    streammux.set_property('batched-push-timeout', 4000000)\n",
    "\n",
    "    #Set properties of pgie and sgie\n",
    "    pgie.set_property('config-file-path', \"dstest2_pgie_config.txt\")\n",
    "    sgie1.set_property('config-file-path', \"dstest2_sgie1_config.txt\")\n",
    "    sgie2.set_property('config-file-path', \"dstest2_sgie2_config.txt\")\n",
    "    sgie3.set_property('config-file-path', \"dstest2_sgie3_config.txt\")\n",
    "\n",
    "    #Set properties of tracker\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dstest2_tracker_config.txt')\n",
    "    config.sections()\n",
    "\n",
    "    for key in config['tracker']:\n",
    "        if key == 'tracker-width' :\n",
    "            tracker_width = config.getint('tracker', key)\n",
    "            tracker.set_property('tracker-width', tracker_width)\n",
    "        if key == 'tracker-height' :\n",
    "            tracker_height = config.getint('tracker', key)\n",
    "            tracker.set_property('tracker-height', tracker_height)\n",
    "        if key == 'gpu-id' :\n",
    "            tracker_gpu_id = config.getint('tracker', key)\n",
    "            tracker.set_property('gpu_id', tracker_gpu_id)\n",
    "        if key == 'll-lib-file' :\n",
    "            tracker_ll_lib_file = config.get('tracker', key)\n",
    "            tracker.set_property('ll-lib-file', tracker_ll_lib_file)\n",
    "        if key == 'll-config-file' :\n",
    "            tracker_ll_config_file = config.get('tracker', key)\n",
    "            tracker.set_property('ll-config-file', tracker_ll_config_file)\n",
    "        if key == 'enable-batch-process' :\n",
    "            tracker_enable_batch_process = config.getint('tracker', key)\n",
    "            tracker.set_property('enable_batch_process', tracker_enable_batch_process)\n",
    "        if key == 'enable-past-frame' :\n",
    "            tracker_enable_past_frame = config.getint('tracker', key)\n",
    "            tracker.set_property('enable_past_frame', tracker_enable_past_frame)\n",
    "\n",
    "    print(\"Adding elements to Pipeline \\n\")\n",
    "    pipeline.add(source)\n",
    "    pipeline.add(h264parser)\n",
    "    pipeline.add(decoder)\n",
    "    pipeline.add(streammux)\n",
    "    pipeline.add(pgie)\n",
    "    pipeline.add(tracker)\n",
    "    pipeline.add(sgie1)\n",
    "    pipeline.add(sgie2)\n",
    "    pipeline.add(sgie3)\n",
    "    pipeline.add(nvvidconv)\n",
    "    pipeline.add(nvosd)\n",
    "    pipeline.add(sink)\n",
    "\n",
    "    # we link the elements together\n",
    "    # file-source -> h264-parser -> nvh264-decoder ->\n",
    "    # nvinfer -> nvvidconv -> nvosd -> video-renderer\n",
    "    print(\"Linking elements in the Pipeline \\n\")\n",
    "    source.link(h264parser)\n",
    "    h264parser.link(decoder)\n",
    "\n",
    "    sinkpad = streammux.get_request_pad(\"sink_0\")\n",
    "    if not sinkpad:\n",
    "        sys.stderr.write(\" Unable to get the sink pad of streammux \\n\")\n",
    "    srcpad = decoder.get_static_pad(\"src\")\n",
    "    if not srcpad:\n",
    "        sys.stderr.write(\" Unable to get source pad of decoder \\n\")\n",
    "    srcpad.link(sinkpad)\n",
    "    streammux.link(pgie)\n",
    "    pgie.link(tracker)\n",
    "    tracker.link(sgie1)\n",
    "    sgie1.link(sgie2)\n",
    "    sgie2.link(sgie3)\n",
    "    sgie3.link(nvvidconv)\n",
    "    nvvidconv.link(nvosd)\n",
    "    nvosd.link(sink)\n",
    "\n",
    "\n",
    "    # create and event loop and feed gstreamer bus mesages to it\n",
    "    loop = GLib.MainLoop()\n",
    "\n",
    "    bus = pipeline.get_bus()\n",
    "    bus.add_signal_watch()\n",
    "    bus.connect (\"message\", bus_call, loop)\n",
    "\n",
    "    # Lets add probe to get informed of the meta data generated, we add probe to\n",
    "    # the sink pad of the osd element, since by that time, the buffer would have\n",
    "    # had got all the metadata.\n",
    "    osdsinkpad = nvosd.get_static_pad(\"sink\")\n",
    "    if not osdsinkpad:\n",
    "        sys.stderr.write(\" Unable to get sink pad of nvosd \\n\")\n",
    "    osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe, 0)\n",
    "\n",
    "\n",
    "    print(\"Starting pipeline \\n\")\n",
    "    \n",
    "    # start play back and listed to events\n",
    "    pipeline.set_state(Gst.State.PLAYING)\n",
    "    try:\n",
    "      loop.run()\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # cleanup\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main(sys.argv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayimg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "cv2.imshow(\"gray\",grayimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left = img[0:center[1], 0:center[0]]\n",
    "top_right = img[0:center[1], center[0]:width]\n",
    "# bottom_left = img[center[1]:height, 0:center[0]]\n",
    "# bottom_right = img[center[1]:height, center[0]:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow(\"Tleft\",top_left)\n",
    "cv2.imshow(\"tright\",top_right)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(top_left, cv2.COLOR_BGR2GRAY)\n",
    "gray=cv2.GaussianBlur(gray,(7,7),0)\n",
    "edges = cv2.Canny(gray,70,220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray\",gray)\n",
    "cv2.imshow(\"EDGES\",edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "largest_contour = max(contours, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the bounding box\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "cv2.rectangle(top_left, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",top_left)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(top_right, cv2.COLOR_BGR2GRAY)\n",
    "gray=cv2.GaussianBlur(gray,(3,3),0)\n",
    "edges = cv2.Canny(gray, 50, 190)\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "cv2.rectangle(top_right, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"TRimg\",top_right)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0:center[1], 0:center[0]] = top_left\n",
    "# cv2.imshow(\"TLimg\",top_left)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0:center[1], center[0]:width] = top_right\n",
    "# cv2.imshow(\"TRimg\",top_right)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final image\n",
    "cv2.imshow('Output image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "img = cv2.imread('crane.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray=cv2.GaussianBlur(gray,(3,3),0)\n",
    "edges = cv2.Canny(gray,85,255)\n",
    "# cv2.imshow(\"original\",img)\n",
    "# cv2.imshow(\"gray\",gray)\n",
    "# cv2.imshow(\"edges\",edges)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 1, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=50, minLineLength=50, maxLineGap=5)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections = []\n",
    "for i in range(len(lines)):\n",
    "    for j in range(i+1, len(lines)):\n",
    "        line1 = lines[i][0]\n",
    "        line2 = lines[j][0]\n",
    "        x1, y1, x2, y2 = line1\n",
    "        x3, y3, x4, y4 = line2\n",
    "        determinant = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        if determinant != 0:\n",
    "            ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / determinant\n",
    "            ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / determinant\n",
    "            if 0 < ua < 1 and 0 < ub < 1:\n",
    "                x = int(x1 + ua*(x2-x1))\n",
    "                y = int(y1 + ua*(y2-y1))\n",
    "                intersections.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('straight lines',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in intersections:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        dist_to_line = cv2.pointPolygonTest(np.array([(x1,y1), (x2,y2)]), point, True)\n",
    "        if dist_to_line < 2: # check if the distance is within a certain threshold\n",
    "            cv2.circle(img, point, 5, (255, 0, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Intersection Points Detected', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
